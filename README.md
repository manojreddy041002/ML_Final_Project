# Vision LLM MNIST ML Final Project

> This project compares MNIST digit recognition using a trained CNN versus zero-shot Vision-LLM inference via LLaVA on Ollama. The system classifies digits locally from a prompt and image, showing that while CNNs reach ~99% accuracy, Vision-LLMs provide flexible, human-readable, training-free predictions.
